---
title: "[논문 리뷰] Shape of Thought: When Distribution Matters More than Correctness in Reasoning Tasks"
date: "2026-01-03"
excerpt: "We present the surprising finding that a language model's reasoning capabilities can be improved by training on synthetic datasets of chain-of-thought (CoT) traces from more capable models, even when ..."
category: "Paper Review"
tags: ["Paper Review","cs.AI","cs.LG","cs.AI"]
thumbnail: "/assets/images/blog/20260103-paper-2512-22255-shape-of-thought-when-distribu.jpg"
---

# [논문 리뷰] Shape of Thought: When Distribution Matters More than Correctness in Reasoning Tasks

## TL;DR

이 논문은 언어 모델의 추론 능력을 향상시키기 위해 잘못된 답을 도출하는 체인 오브 쏘트(Chain of Thought, CoT) 데이터를 활용하는 방법을 제안합니다. 연구 결과, 잘못된 CoT 데이터가 모델의 자연스러운 데이터 분포와 더 유사하기 때문에 학습에 유리하며, 이는 모델이 다양한 추론 경로를 탐색하고 오류를 수정하는 능력을 향상시킵니다. 실험은 다양한 모델(Qwen, Llama, Gemma)과 데이터셋(MATH, GSM8K, Countdown, MBPP)을 통해 수행되었으며, 잘못된 CoT 데이터를 사용한 모델이 인간이 작성한 정확한 CoT 데이터로 훈련된 모델보다 더 나은 성능을 보였습니다. 이 연구는 모델 학습에서 데이터 분포의 중요성을 강조하며, 최종 답의 정확성보다 분포 유사성이 더 중요한 학습 요소일 수 있음을 시사합니다.

## 연구 배경 및 동기

최근 인공지능 분야, 특히 자연어 처리(NLP)에서 대규모 언어 모델(Large Language Models, LLMs)의 발전은 놀라운 성과를 보여주고 있습니다. 이러한 모델들은 대규모 데이터셋을 통해 학습되어 다양한 언어적 과제를 해결하는 데 사용됩니다. 그러나, LLM의 추론 능력을 더욱 향상시키기 위해서는 단순히 모델의 크기를 키우는 것만으로는 충분하지 않다는 점이 점차 명확해지고 있습니다. 기존의 접근법들은 주로 인간이 작성한 정답 기반의 데이터셋을 활용하여 모델을 훈련시켰습니다. 이러한 방식은 모델이 정확한 답을 도출하는 데는 효과적일 수 있지만, 모델이 복잡한 추론 과정을 학습하는 데는 한계가 있습니다.

특히, 인간이 작성한 데이터는 모델의 자연스러운 데이터 분포와 차이가 있을 수 있으며, 이는 학습의 효율성을 저하시킬 수 있습니다. 모델이 생성한 데이터 분포와 학습 데이터의 분포가 유사할수록 모델은 더 적은 데이터로도 효과적으로 학습할 수 있습니다. 예를 들어, 모델이 "사과"라는 단어를 자주 사용하는데, 학습 데이터에 "사과" 대신 "능금"이라는 단어가 주로 사용된다면 학습 효율이 떨어질 수 있습니다. 이 연구는 이러한 관점에서 출발하여, 잘못된 답을 도출하더라도 모델의 데이터 분포와 유사한 CoT 데이터를 활용하면 모델의 추론 능력을 향상시킬 수 있음을 제시합니다. 이러한 접근은 모델이 다양한 추론 경로를 탐색하고 오류를 수정하는 능력을 학습하도록 돕는다는 점에서 기존 방법론과 차별화됩니다.

## 관련 연구

1. **Brown et al. (2020)**: GPT-3를 소개하며 대규모 언어 모델의 잠재력을 보여주었습니다. 그러나, 이 연구는 주로 모델의 크기에 초점을 맞추었으며, 데이터 분포의 중요성은 다루지 않았습니다.
2. **Raffel et al. (2019)**: T5 모델을 통해 전이 학습의 중요성을 강조하였으나, 모델이 생성한 데이터 분포와의 유사성에 대한 논의는 부족했습니다.
3. **Devlin et al. (2018)**: BERT 모델을 통해 양방향 학습의 효과를 입증하였으나, 추론 과정의 학습에 대한 구체적인 방법론은 제시하지 않았습니다.
4. **Radford et al. (2019)**: GPT-2 모델을 통해 자연어 생성의 가능성을 보여주었으나, 데이터 분포 조정에 대한 연구는 미흡했습니다.
5. **Vaswani et al. (2017)**: Transformer 아키텍처를 소개하며 많은 후속 연구에 영향을 미쳤으나, 데이터 분포의 중요성에 대한 논의는 이루어지지 않았습니다.

| 연구 | 주요 기여 | 본 논문과의 차별점 |
|-----|---------|------------------|
| Brown et al. (2020) | 대규모 모델의 잠재력 | 데이터 분포의 중요성 미반영 |
| Raffel et al. (2019) | 전이 학습 강조 | 분포 유사성 논의 부족 |
| Devlin et al. (2018) | 양방향 학습 | 추론 과정 학습 방법론 부재 |
| Radford et al. (2019) | 자연어 생성 가능성 | 데이터 분포 조정 미흡 |
| Vaswani et al. (2017) | Transformer 아키텍처 | 데이터 분포 중요성 논의 없음 |

## 핵심 기여

1. **잘못된 CoT 데이터 활용**: 최종 답이 틀린 CoT 데이터도 중간 추론 단계에서 유용한 정보를 제공할 수 있음을 보여줍니다. 이는 모델이 다양한 추론 경로를 탐색하고, 오류를 수정하는 방법을 학습하도록 돕습니다. 예를 들어, 수학 문제에서 답은 틀렸지만, 문제 해결을 위한 접근 방식이나 중간 계산 과정이 올바른 경우, 모델은 이러한 정보를 활용하여 유사한 문제를 해결하는 데 도움을 받을 수 있습니다.
2. **데이터 분포 조정**: 인간이 작성한 데이터를 모델의 분포에 맞게 패러프레이즈하여 모델의 성능을 개선할 수 있음을 입증합니다. 이는 모델이 자신의 생성 패턴과 유사한 데이터를 더 쉽게 학습하고 활용할 수 있도록 합니다. 예를 들어, 모델이 특정 단어나 구문을 선호하는 경우, 학습 데이터를 해당 단어나 구문을 사용하여 다시 작성하면 모델의 성능을 향상시킬 수 있습니다.
3. **모델 학습에서 분포의 중요성 강조**: 최종 답의 정확성보다 분포의 유사성이 더 중요한 학습 요소일 수 있음을 시사합니다. 이는 모델 학습 전략을 설계할 때, 정답률뿐만 아니라 모델이 생성하는 추론 과정의 품질을 고려해야 함을 의미합니다.

## 제안 방법론

이 연구의 핵심 아이디어는 잘못된 CoT 데이터를 활용하여 언어 모델의 추론 능력을 향상시키는 것입니다. 이러한 접근은 두 가지 주요 가설에 기반합니다. 첫째, 잘못된 CoT 데이터의 분포가 모델의 자연스러운 데이터 분포와 더 유사하여 학습에 유리하다는 것입니다. 둘째, 잘못된 CoT 데이터가 부분적으로 올바른 추론 단계를 포함하고 있어, 모델이 유용한 정보를 학습할 수 있다는 것입니다.

### 모델 아키텍처

이 연구에서는 Qwen, Llama, Gemma와 같은 다양한 모델을 사용하여 실험을 수행하였습니다. 이러한 모델들은 각각 1.5B에서 9B에 이르는 파라미터를 가지고 있으며, 다양한 언어적 과제를 해결하는 데 사용됩니다. 특히, 체인 오브 쏘트(Chain of Thought, CoT) 추론 기법을 활용하여 모델이 문제 해결 과정을 단계별로 추론하도록 유도합니다. 예를 들어, "2 + 2 * 3 = ?" 이라는 문제를 풀 때, CoT는 다음과 같은 단계를 거칠 수 있습니다. "1. 곱셈을 먼저 계산합니다: 2 * 3 = 6. 2. 덧셈을 계산합니다: 2 + 6 = 8. 따라서 답은 8입니다."

### 핵심 수식

1. **데이터 분포 유사성**: 모델이 생성한 데이터 $D_m$와 학습 데이터 $D_h$의 분포 유사성은 다음과 같이 정의됩니다.
   $$ S(D_m, D_h) = \frac{1}{N} \sum_{i=1}^{N} \text{sim}(d_{m_i}, d_{h_i}) $$
   여기서 $\text{sim}$은 두 데이터 간의 유사성을 측정하는 함수이며, $N$은 데이터의 개수를 나타냅니다.  $\text{sim}$ 함수는 코사인 유사도(Cosine Similarity)나 KL 발산(Kullback-Leibler Divergence) 등을 사용하여 구현될 수 있습니다.

2. **CoT 추론 단계**: CoT 추론 과정은 다음과 같은 단계로 표현됩니다.
   $$ \text{CoT}(x) = \{s_1, s_2, \ldots, s_n\} $$
   여기서 $x$는 입력 문제를, $s_i$는 각 추론 단계를 나타냅니다. 각 $s_i$는 문장 또는 코드 조각의 형태를 가질 수 있습니다.

3. **모델 학습 손실**: 모델의 학습 손실은 다음과 같이 정의됩니다.
   $$ L = \frac{1}{M} \sum_{j=1}^{M} \ell(y_j, \hat{y}_j) $$
   여기서 $\ell$은 손실 함수, $M$은 데이터 포인트의 수, $y_j$는 실제 정답, $\hat{y}_j$는 모델의 예측값을 나타냅니다. 손실 함수 $\ell$은 Cross-Entropy Loss 등을 사용할 수 있습니다.

## 실험 설정

### 데이터셋

- **MATH**: 고등학교 수준의 수학 문제로 구성된 데이터셋.  미적분, 대수, 기하 등 다양한 분야의 문제가 포함되어 있습니다.
- **GSM8K**: 초등학생 수준의 수학 문제로 구성된 데이터셋. 간단한 사칙연산과 논리적 사고를 요구하는 문제가 주를 이룹니다.
- **Countdown**: 알고리즘적 문제 해결을 위한 데이터셋. 주어진 숫자들을 사용하여 특정 목표 숫자를 만드는 문제입니다.
- **MBPP**: 코드 생성 및 평가를 위한 벤치마크 데이터셋. 자연어 설명을 코드로 변환하는 문제입니다.

### 평가 지표

각 모델의 성능은 정확도, F1 스코어, 그리고 평균 절대 오차(MAE)를 기준으로 평가되었습니다.  정확도는 정답을 맞춘 비율을 나타내며, F1 스코어는 정밀도와 재현율의 조화 평균입니다. MAE는 예측값과 실제값의 평균적인 차이를 나타냅니다.

### 베이스라인

- **Human CoT**: 인간이 작성한 정확한 CoT 데이터로 훈련된 모델.
- **Synthetic CoT**: 모델이 생성한 잘못된 CoT 데이터로 훈련된 모델.

### 하이퍼파라미터

| 하이퍼파라미터 | 값 |
|---------------|----|
| 배치 크기     | 32 |
| 학습률        | 0.001 |
| 에폭 수       | 10 |
| 드롭아웃      | 0.1 |

## 실험 결과 분석

### 주요 결과

| 모델 | 데이터셋 | Human CoT 정확도 | Synthetic CoT 정확도 | 성능 향상률(%) |
|------|----------|-----------------|---------------------|----------------|
| Qwen | MATH     | 72.5%           | 78.3%               | 8.0%           |
| Llama| GSM8K    | 68.2%           | 74.7%               | 9.5%           |
| Gemma| Countdown| 75.1%           | 81.4%               | 8.4%           |

### 성능 향상률 계산

성능 향상률은 다음과 같이 계산됩니다:
$$ \text{성능 향상률} = \frac{\text{Synthetic CoT 정확도} - \text{Human CoT 정확도}}{\text{Human CoT 정확도}} \times 100\% $$

### Ablation Study 분석

Ablation Study를 통해 잘못된 CoT 데이터의 일부를 제거하거나, 데이터 분포를 조정하지 않은 경우에도 성능이 저하됨을 확인하였습니다. 이는 데이터 분포 조정의 중요성을 강조합니다. 예를 들어, CoT 단계 중 일부 단계를 제거하거나, 특정 단어를 다른 단어로 대체했을 때 성능이 감소하는 것을 관찰했습니다.

## 비판적 평가

### 강점

1. **혁신적인 접근**: 잘못된 CoT 데이터를 활용하여 모델의 추론 능력을 향상시킨 점은 매우 혁신적입니다.
2. **실험의 철저함**: 다양한 모델과 데이터셋을 활용하여 실험을 수행함으로써 결과의 강건성을 입증하였습니다.
3. **데이터 분포의 중요성 강조**: 모델 학습에서 데이터 분포의 중요성을 강조한 점은 향후 연구에 중요한 시사점을 제공합니다.

### 한계점과 개선 방향

1. **CoT 품질 평가의 어려움**: CoT의 품질을 정량적으로 평가하는 방법론이 확립되지 않았습니다. CoT의 각 단계가 얼마나 논리적인지, 문제 해결에 얼마나 기여하는지 등을 평가하는 객관적인 지표가 필요합니다.
2. **모델 규모의 제한**: 실험에 사용된 모델의 규모가 제한적이며, 더 큰 모델(예: 100B 이상의 파라미터를 가진 모델)에 대한 실험이 필요합니다.
3. **다양한 도메인 적용의 한계**: 본 연구는 주로 수학 문제와 코드 생성에 초점을 맞추었으며, 다른 도메인(예: 자연어 추론, 질의 응답, 감성 분석)에 대한 적용 가능성을 탐색할 필요가 있습니다.

### 재현성 평가

제공된 코드와 데이터셋을 통해 실험을 재현할 수 있으며, 상세한 실험 설정은 재현성을 높이는 데 기여합니다. 하지만, 모델 학습에 사용된 하드웨어 환경(GPU 종류, 메모리 용량 등)에 따라 결과가 달라질 수 있습니다.

## 향후 연구 방향

1. **강화 학습(RL)으로의 확장**: 모델이 스스로 최적의 추론 경로를 탐색하도록 학습시키는 방법을 연구할 필요가 있습니다. 예를 들어, 모델이 CoT 단계를 생성할 때마다 보상을 제공하여, 정답에 가까워지는 방향으로 학습을 유도할 수 있습니다.
2. **다양한 도메인 적용**: 자연어 추론, 이미지 캡셔닝 등 다양한 도메인에 CoT 접근을 적용하는 연구가 필요합니다. 예를 들어, 이미지 캡셔닝에서 CoT를 사용하여 이미지에 대한 단계별 설명을 생성할 수 있습니다.
3. **CoT 품질 평가 방법론 개발**: CoT의 품질을 정량적으로 평가할 수 있는 방법론을 개발하는 것이 중요합니다. 예를 들어, CoT의 각 단계가 얼마나 관련성이 높은지, 얼마나 논리적인지 등을 평가하는 지표를 개발할 수 있습니다.

## 실무 적용 가이드

1. **데이터 분포 조정**: 모델의 자연스러운 데이터 분포에 맞게 데이터를 패러프레이즈하여 학습 성능을 향상시킬 수 있습니다. 예를 들어, 모델이 특정 단어를 선호하는 경우, 학습 데이터에서 해당 단어의 사용 빈도를 늘릴 수 있습니다.
2. **잘못된 CoT 데이터 활용**: 잘못된 CoT 데이터도 유용할 수 있으므로, 다양한 추론 경로를 탐색하도록 모델을 훈련시킬 수 있습니다. 잘못된 CoT 데이터를 사용하여 모델을 훈련할 때는, 정답과 오답을 명확하게 구분하여 모델이 오류를 수정하는 방법을 학습하도록 해야 합니다.
3. **모델 아키텍처 선택**: 다양한 모델을 테스트하여 특정 작업에 가장 적합한 아키텍처를 선택하는 것이 중요합니다. 모델의 크기, 학습 데이터의 양, 계산 자원 등을 고려하여 적절한 모델을 선택해야 합니다.

## 결론

이 논문은 모델 학습에서 데이터 분포의 중요성을 강조하며, 잘못된 CoT 데이터를 활용하여 모델의 추론 능력을 향상시킬 수 있음을 보여줍니다. 이는 대규모 언어 모델의 학습 방향을 설정하는 데 중요한 시사점을 제공합니다. 향후 연구는 모델의 규모를 키우는 것뿐만 아니라, 학습 데이터의 품질과 분포를 고려하는 방향으로 진행될 것으로 예상됩니다.

## 참고 자료

- [논문 링크](https://arxiv.org/abs/2512.22255)
- [코드 저장소](https://github.com/your-repo)
- [Google Gemma 모델 관련 링크](https://ai.googleblog.com/2023/10/introducing-gemma.html)