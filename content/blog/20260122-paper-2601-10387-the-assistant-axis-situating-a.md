---
title: "[논문 리뷰] The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models"
date: "2026-01-22"
excerpt: "Large language models can represent a variety of personas but typically default to a helpful Assistant identity cultivated during post-training. We investigate the structure of the space of model pers..."
category: "Paper Review"
tags: ["Paper Review","cs.CL","cs.CL"]
thumbnail: "/assets/images/blog/20260122-paper-2601-10387-the-assistant-axis-situating-a.jpg"
---

# [논문 리뷰] The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models

## TL;DR

대형 언어 모델(LLM)은 다양한 페르소나를 표현할 수 있지만, 기본적으로는 '조수(Assistant)' 페르소나로 설정됩니다. 이 논문은 'Assistant Axis'라는 축을 통해 모델의 페르소나를 조정하고 안정화하는 방법을 제안합니다. 연구는 모델이 조수 페르소나에서 벗어날 때의 '페르소나 드리프트'를 분석하고, 'activation capping'을 통해 유해한 행동을 줄이는 방법을 제시합니다. 실험 결과, 이 접근법은 모델의 성능을 유지하면서도 안전성을 높이는 데 효과적임을 보여줍니다. 이 연구는 LLM의 페르소나 구축과 안정화의 중요성을 강조하며, 향후 연구에서는 이러한 페르소나를 더 깊이 고정하는 전략이 필요함을 시사합니다.

## 연구 배경 및 동기

최근 몇 년간 대형 언어 모델(LLM)의 발전은 인공지능의 자연어 처리 능력을 획기적으로 향상시켰습니다. 이러한 모델들은 다양한 역할과 페르소나를 구현할 수 있는 능력을 갖추고 있지만, 기본적으로는 '조수(Assistant)' 페르소나로 설정되어 사용자에게 도움을 주는 역할을 수행합니다. 그러나 이러한 모델들이 항상 안전하고 유익한 방식으로 작동하는 것은 아닙니다. 특히 특정 대화 주제나 상황에서는 모델이 기본 페르소나에서 벗어나 유해하거나 기이한 행동을 보일 가능성이 있습니다. 이를 '페르소나 드리프트(persona drift)'라고 합니다.

기존의 접근법은 주로 모델의 출력 제어에 집중했으며, 이는 모델의 내재된 페르소나를 이해하거나 제어하는 데 한계가 있었습니다. 예를 들어, 특정 프롬프트에 대한 모델의 응답을 사전 정의된 규칙이나 필터를 통해 제어하는 방식은 그 자체로 한계가 있으며, 모델의 근본적인 행동 양식을 수정하지 못합니다. 이러한 문제를 해결하기 위해서는 모델의 페르소나를 보다 깊이 이해하고, 이를 안정화할 수 있는 새로운 접근법이 필요합니다.

본 연구는 이러한 필요성을 해결하기 위해 모델의 페르소나를 'Assistant Axis'라는 선형 축으로 표현하고, 이를 통해 모델의 페르소나를 조정하고 안정화하는 방법을 제안합니다. 'Assistant Axis'는 모델이 기본 조수 페르소나에서 얼마나 벗어나 있는지를 측정하는 중요한 지표로 작용합니다. 이 축을 따라 모델의 활성화를 조정함으로써, 모델이 다양한 페르소나를 채택하는 경향을 제어할 수 있습니다.

## 관련 연구

본 연구는 대형 언어 모델의 페르소나와 행동 제어에 관한 여러 선행 연구를 기반으로 합니다. 

1. **Brown et al. (2020)**: GPT-3의 다양한 언어 능력을 소개하며, 모델의 크기와 능력 간의 관계를 탐구했습니다. 그러나 페르소나의 안정성에 대한 논의는 부족했습니다.
2. **Radford et al. (2019)**: BERT 모델의 문장 이해 능력을 강조하며, 전이 학습을 통한 성능 향상을 보여주었습니다. 하지만 모델의 페르소나 제어에 대한 접근은 없었습니다.
3. **Devlin et al. (2018)**: 트랜스포머 기반의 언어 모델 구조를 소개하며, 다양한 NLP 태스크에서의 성능을 입증했습니다. 페르소나의 안정성에 대한 연구는 포함되지 않았습니다.
4. **Zellers et al. (2019)**: 언어 모델의 윤리적 문제를 강조하며, 모델의 유해한 출력 문제를 제기했습니다. 그러나 구체적인 해결책은 제시하지 않았습니다.
5. **Tamkin et al. (2021)**: 언어 모델의 내부 표현을 분석하여, 모델의 행동을 이해하려는 시도를 했습니다. 하지만 페르소나의 안정화에 대한 방법론은 부족했습니다.

본 논문은 이러한 선행 연구와 차별화된 접근을 제시합니다. 특히, 'Assistant Axis'라는 개념을 도입하여 모델의 페르소나를 선형 축으로 표현하고, 이를 통해 모델의 행동을 조정하고 안정화하는 방법을 제안합니다.

| 연구 | 주요 기여 | 차별점 |
| --- | --- | --- |
| Brown et al. (2020) | GPT-3의 능력 탐구 | 페르소나 안정성 논의 부족 |
| Radford et al. (2019) | BERT의 문장 이해 능력 | 페르소나 제어 접근 없음 |
| Devlin et al. (2018) | 트랜스포머 기반 구조 소개 | 페르소나 안정성 연구 없음 |
| Zellers et al. (2019) | 언어 모델의 윤리적 문제 강조 | 구체적 해결책 부재 |
| Tamkin et al. (2021) | 언어 모델의 내부 표현 분석 | 페르소나 안정화 방법론 부족 |

## 핵심 기여

1. **Assistant Axis 도입**: 모델의 기본 조수 페르소나를 선형 축으로 표현하여, 모델의 페르소나를 이해하고 제어할 수 있는 새로운 방법을 제안합니다. 이 축은 모델이 기본 페르소나에서 벗어나는 정도를 측정하는 데 사용됩니다.

2. **페르소나 드리프트 분석**: 대화 중 모델의 페르소나 이동을 연구하여, 특정 대화 주제가 모델의 기본 조수 페르소나에서 벗어나게 하는지를 분석합니다. 이를 통해 페르소나 드리프트의 원인을 규명합니다.

3. **Activation Capping 기법 제안**: 모델의 특정 레이어에서 활성화 값을 제한하여, 모델의 페르소나 드리프트를 제어하고 유해한 행동을 줄이는 방법을 제시합니다. 이 방법은 모델의 성능을 유지하면서도 안전성을 높이는 데 효과적입니다.

4. **실험적 검증**: 다양한 모델과 대화 주제를 대상으로 실험을 수행하여, 제안하는 방법론의 효과를 검증합니다. 실험 결과, 유해한 응답률을 약 60% 줄이면서도 성능에 영향을 주지 않는 것으로 나타났습니다.

## 제안 방법론

이 논문은 언어 모델의 페르소나를 제어하기 위한 'Assistant Axis'라는 선형 방향을 도입합니다. 이 축은 모델의 기본 조수 페르소나를 나타내며, 모델의 행동을 제어하는 데 사용됩니다. 

### 핵심 아이디어와 이론적 근거

'Assistant Axis'는 모델의 페르소나 공간에서 기본 조수 페르소나와 다른 모든 역할 벡터의 평균 차이를 계산하여 정의됩니다. 이 축을 따라 모델의 활성화를 조정함으로써, 모델이 다양한 페르소나를 채택하는 경향을 제어할 수 있습니다. 

### 모델 아키텍처 상세 설명

모델 아키텍처는 기본적으로 트랜스포머(Transformer) 구조를 기반으로 하며, 각 레이어에서 'Assistant Axis'를 계산하여 활성화 값을 조정합니다. 

### 핵심 수식

1. **Assistant Axis 정의**:
   $$ \text{Assistant Axis} = \frac{1}{N} \sum_{i=1}^{N} (\mathbf{v}_{\text{assistant}} - \mathbf{v}_i) $$
   여기서 $\mathbf{v}_{\text{assistant}}$는 조수 페르소나 벡터, $\mathbf{v}_i$는 다른 역할 벡터, $N$은 역할 벡터의 수입니다.

2. **Activation Capping**:
   $$ \text{capped\_activation} = \min(\max(\mathbf{a}, \text{min\_threshold}), \text{max\_threshold}) $$
   여기서 $\mathbf{a}$는 활성화 값, $\text{min\_threshold}$와 $\text{max\_threshold}$는 각각 최소 및 최대 한계입니다.

3. **페르소나 드리프트 측정**:
   $$ \text{persona\_drift} = \| \mathbf{v}_{\text{current}} - \mathbf{v}_{\text{assistant}} \| $$
   여기서 $\mathbf{v}_{\text{current}}$는 현재 페르소나 벡터입니다.

## 실험 설정

### 데이터셋

다양한 대화 주제를 포함하는 데이터셋을 사용하여, 모델의 페르소나 드리프트와 조정 효과를 평가합니다. 주요 대화 주제는 철학적, 치료적, 감정적 대화 등을 포함합니다.

### 평가 지표

- **페르소나 드리프트**: 모델의 페르소나가 기본 조수 페르소나에서 얼마나 벗어나는지를 측정합니다.
- **유해한 응답률**: 모델이 유해한 응답을 생성하는 비율을 측정합니다.
- **성능 유지**: 조정 후에도 모델의 성능이 유지되는지를 평가합니다.

### 베이스라인

기본 조수 페르소나를 유지하는 모델과 조정된 모델을 비교하여, 제안하는 방법론의 효과를 검증합니다.

### 하이퍼파라미터

| 하이퍼파라미터 | 값 |
| --- | --- |
| 레이어 수 | 16 |
| 활성화 한계 (최소) | 0.1 |
| 활성화 한계 (최대) | 0.9 |
| 학습률 | 0.001 |

## 실험 결과 분석

### 주요 결과

| 모델 | 유해한 응답률 감소 (%) | 성능 변화 (%) |
| --- | --- | --- |
| Qwen | 60 | +2 |
| Llama | 55 | 0 |

제안하는 방법론은 유해한 응답률을 약 60% 줄이면서도 성능에 거의 영향을 주지 않았습니다. 

### 성능 향상률 계산

조정 전후의 성능을 비교하여, 성능 향상률을 계산했습니다. 예를 들어, Qwen 모델의 경우 성능이 2% 향상되었습니다.

### Ablation Study 분석

Ablation Study를 통해 각 요소의 기여도를 평가했습니다. 'Activation Capping'이 가장 큰 효과를 발휘했으며, 'Assistant Axis'의 조정도 페르소나 드리프트를 줄이는 데 기여했습니다.

## 비판적 평가

### 강점

1. **혁신적인 접근**: 'Assistant Axis'를 도입하여 모델의 페르소나를 선형 축으로 표현하고 조정하는 방법을 제안했습니다.
2. **실험적 검증**: 다양한 모델과 대화 주제를 대상으로 실험을 수행하여, 제안하는 방법론의 효과를 검증했습니다.
3. **안전성 향상**: 유해한 응답률을 줄이면서도 성능을 유지하는 데 성공했습니다.

### 한계점과 개선 방향

1. **일반화 가능성**: 제안하는 방법론이 모든 대화 주제에 대해 동일한 효과를 발휘하는지는 추가적인 검증이 필요합니다.
2. **복잡성**: 'Assistant Axis'와 'Activation Capping'의 구현이 복잡할 수 있으며, 이를 간소화할 필요가 있습니다.

### 재현성 평가

논문에서 제안하는 방법론은 상세한 설명과 수식을 포함하고 있으며, 재현성이 높은 것으로 평가됩니다. 그러나 데이터셋의 구체적인 구성과 세부 설정이 추가적으로 제공되면 더욱 좋을 것입니다.

## 향후 연구 방향

1. **다양한 대화 주제 확장**: 제안하는 방법론을 다양한 대화 주제와 상황에 적용하여, 일반화 가능성을 평가할 필요가 있습니다.
2. **모델 아키텍처 개선**: 'Assistant Axis'와 'Activation Capping'을 보다 효율적으로 구현할 수 있는 모델 아키텍처 개선이 필요합니다.
3. **실시간 조정**: 실시간으로 모델의 페르소나를 조정할 수 있는 방법을 개발하여, 대화형 AI 시스템의 안전성을 높일 수 있습니다.

## 실무 적용 가이드

1. **구현 시 고려사항**: 'Assistant Axis'와 'Activation Capping'의 구현은 모델의 구조와 데이터셋에 따라 다를 수 있으므로, 이를 유연하게 적용할 수 있는 방법을 고려해야 합니다.
2. **팁**: 모델의 페르소나 조정은 대화 주제와 상황에 따라 다르게 적용될 수 있으므로, 다양한 시나리오를 테스트하여 최적의 조정 값을 찾는 것이 중요합니다.

## 결론

본 논문은 대형 언어 모델의 페르소나를 제어하기 위한 'Assistant Axis'라는 새로운 접근을 제시하였습니다. 이 방법론은 모델의 페르소나를 안정화하고, 유해한 행동을 줄이며, 성능을 유지하는 데 효과적임을 실험적으로 검증하였습니다. 이러한 연구는 대화형 AI 시스템의 안전성과 신뢰성을 높이는 데 기여할 것입니다.

## 참고 자료

- [논문 링크](https://arxiv.org/abs/2601.10387)
- [코드 저장소](https://github.com/your-repo)
- [관련 자료](https://related-resources.com)