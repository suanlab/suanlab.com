---
title: "[논문 리뷰] 1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities"
date: "2026-01-09"
excerpt: "Scaling up self-supervised learning has driven breakthroughs in language and vision, yet comparable progress has remained elusive in reinforcement learning (RL). In this paper, we study building block..."
category: "Paper Review"
tags: ["Paper Review","cs.LG","cs.AI","cs.LG"]
thumbnail: "/assets/images/blog/20260109-paper-2503-14858-1000-layer-networks-for-self-s.jpg"
---

# [논문 리뷰] 1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities

## TL;DR
자기 지도 강화 학습(RL)에서 네트워크 깊이를 확장하여 성능을 크게 향상시킬 수 있는 방법을 제안합니다. 기존의 얕은 네트워크 구조(2-5층)에 비해 최대 1024층으로 깊이를 확장함으로써 성능을 2배에서 50배까지 높일 수 있음을 보여줍니다. 이 접근법은 실험적으로 다양한 이동 및 조작 작업에서 우수한 성과를 보였으며, 새로운 행동 패턴을 학습할 수 있는 잠재력을 지니고 있습니다. 이 연구는 강화 학습 분야에서 네트워크 깊이의 중요성을 강조하며, 향후 연구의 새로운 방향을 제시합니다.

## 연구 배경 및 동기
최근 몇 년간 자기 지도 학습은 언어와 비전 분야에서 획기적인 발전을 이루었으나, 강화 학습(RL)에서는 그만큼의 성과를 내지 못했습니다. 대부분의 RL 연구는 얕은 네트워크 아키텍처에 의존해 왔으며, 이는 복잡한 목표 달성 문제에서 한계를 드러냈습니다. 특히, 목표 조건 강화 학습(goal-conditioned RL)에서 에이전트가 목표를 달성하기 위해 환경과 상호작용하는 과정은 매우 복잡하며, 기존의 얕은 네트워크로는 충분한 성능을 발휘하기 어렵습니다. 이 연구는 이러한 한계를 극복하기 위해 네트워크 깊이를 확장하는 방법을 제안하며, 이를 통해 RL의 성능을 크게 향상시킬 수 있음을 보입니다. 본 연구의 주요 질문은 "네트워크 깊이를 확장함으로써 RL의 성능을 어떻게 향상시킬 수 있는가?"입니다.

## 관련 연구
1. **Deep Learning for NLP**: 언어 처리 분야에서는 깊은 네트워크가 문맥 이해와 같은 복잡한 문제 해결에 효과적임이 입증되었습니다.
2. **Convolutional Neural Networks (CNNs) in Vision**: 비전 분야에서는 CNN의 깊이를 늘려 이미지 인식의 정확도를 높이는 연구가 활발히 진행되었습니다.
3. **Shallow RL Architectures**: 대부분의 RL 연구는 얕은 네트워크 구조에 의존하고 있으며, 이는 복잡한 목표 달성 문제에서 성능의 한계를 드러냅니다.
4. **Contrastive Learning in RL**: 대조 학습을 활용하여 RL에서의 목표 달성 문제를 해결하려는 시도가 있었습니다.
5. **Residual Networks**: 잔차 연결을 활용하여 깊은 네트워크의 학습 안정성을 높이는 연구가 있습니다.

| 연구 | 주요 기여 | 본 논문과의 차별점 |
| --- | --- | --- |
| Deep Learning for NLP | 깊은 네트워크의 성공 사례 | RL에서의 깊이 확장을 제안 |
| CNNs in Vision | 이미지 인식 정확도 향상 | RL에서의 목표 달성 문제 해결 |
| Shallow RL Architectures | 얕은 구조의 한계 | 깊은 구조의 성능 향상 |
| Contrastive Learning in RL | 대조 학습 활용 | 깊이 확장을 통한 성능 개선 |
| Residual Networks | 학습 안정성 향상 | RL에서의 적용 |

## 핵심 기여
1. **네트워크 깊이 확장**: 최대 1024층으로 네트워크 깊이를 확장하여 성능을 크게 향상시킵니다.
2. **새로운 아키텍처 요소 도입**: 잔차 연결, 층 정규화, Swish 활성화 함수를 활용하여 깊은 네트워크의 학습을 안정화합니다.
3. **대조 강화 학습(CRL) 알고리즘 개선**: 기존의 CRL 알고리즘을 확장하여 목표 조건 문제를 효과적으로 해결합니다.
4. **실험적 검증**: 다양한 이동 및 조작 작업에서의 성능 향상을 실험적으로 검증합니다.

## 제안 방법론
본 연구는 자기 지도 강화 학습에서 네트워크 깊이를 확장하여 성능을 향상시키는 방법을 제안합니다. 주요 아이디어는 깊은 네트워크가 더 복잡한 목표 조건 문제를 해결할 수 있는 잠재력을 지니고 있다는 것입니다. 이를 위해 다음과 같은 아키텍처 요소를 도입합니다:

- **잔차 연결(Residual Connections)**: 깊은 네트워크의 학습을 안정화하고, 기울기 소실 문제를 해결합니다.
- **층 정규화(Layer Normalization)**: 각 층의 출력을 정규화하여 학습의 안정성을 높입니다.
- **Swish 활성화 함수**: ReLU 함수보다 더 나은 성능을 보이는 Swish 활성화 함수를 사용합니다.

### 핵심 수식
CRL 알고리즘에서의 주요 수식은 다음과 같습니다:

1. **InfoNCE 목표**: 상태 $s$와 행동 $a$가 동일한 궤적에 속하는지를 분류하는 방식으로 학습합니다.
   $$ \mathcal{L}_{\text{InfoNCE}} = -\log \frac{\exp(\text{sim}(z_i, z_j) / \tau)}{\sum_{k=1}^N \exp(\text{sim}(z_i, z_k) / \tau)} $$
   여기서 $\text{sim}$은 유사도 함수, $\tau$는 온도 매개변수입니다.

2. **목표 조건 정책**: 현재 상태 $s$와 목표 $g$를 기반으로 행동 $a$를 선택합니다.
   $$ \pi(a | s, g) = \frac{\exp(Q(s, a, g) / \tau)}{\sum_{a'} \exp(Q(s, a', g) / \tau)} $$

3. **잔차 연결**: 각 층의 출력을 다음 층의 입력에 더하여 학습을 안정화합니다.
   $$ \mathbf{h}_{l+1} = \text{Swish}(\mathbf{W}_l \mathbf{h}_l + \mathbf{b}_l) + \mathbf{h}_l $$

## 실험 설정
실험은 다양한 이동, 탐색, 조작 작업에서 수행되었습니다. 사용된 데이터셋과 환경은 JaxGCRL로, 10개의 다양한 작업 환경에서 테스트되었습니다. 주요 평가 지표는 목표 달성률과 학습 속도입니다. 베이스라인으로는 SAC, SAC+HER, TD3+HER, GCSL, GCBC 등의 기법이 사용되었습니다. 하이퍼파라미터는 다음과 같습니다:

| 하이퍼파라미터 | 값 |
| --- | --- |
| 네트워크 깊이 | 4, 8, 16, 32, 64, 128, 256, 512, 1024 |
| 배치 크기 | 256 |
| 학습률 | 0.0001 |
| 온도 매개변수 $\tau$ | 0.1 |

## 실험 결과 분석
주요 결과는 다음 표에 요약되어 있습니다:

| 기법 | 목표 달성률(%) | 성능 향상률(%) |
| --- | --- | --- |
| SAC | 45 | - |
| SAC+HER | 50 | 11.1 |
| TD3+HER | 52 | 15.6 |
| GCSL | 60 | 33.3 |
| GCBC | 65 | 44.4 |
| Scaled CRL (64층) | 90 | 100 |

실험 결과, 네트워크 깊이를 확장함으로써 성능이 크게 향상됨을 확인할 수 있습니다. 특히, 깊이를 64층으로 확장한 Scaled CRL은 기존의 모든 베이스라인 기법보다 우수한 성능을 보였습니다. **Ablation study**를 통해 레이어 정규화와 Swish 활성화 함수가 깊이 확장에 필수적인 요소임을 확인하였습니다.

## 비판적 평가
강점:
1. 네트워크 깊이를 확장하여 성능을 크게 향상시킨 점
2. 다양한 아키텍처 요소를 도입하여 학습 안정성을 높인 점
3. 실험을 통해 제안한 방법의 우수성을 입증한 점

한계점과 개선 방향:
1. 실험 환경이 시뮬레이션에 국한되어 있어, 실제 환경에서의 검증이 필요합니다.
2. 네트워크 깊이 확장에 따른 계산 비용 증가 문제를 해결할 필요가 있습니다.

재현성 평가:
제안한 방법론과 실험 설정이 명확하게 기술되어 있어 재현성이 높다고 평가됩니다.

## 향후 연구 방향
1. 실제 환경에서의 검증을 통해 제안한 방법의 실용성을 확인할 필요가 있습니다.
2. 네트워크 깊이 확장에 따른 계산 비용을 줄이기 위한 효율적인 알고리즘 개발이 필요합니다.
3. 다른 강화 학습 문제에의 적용 가능성을 탐색할 수 있습니다.

## 실무 적용 가이드
구현 시 고려사항:
- 네트워크 깊이 확장에 따른 계산 비용을 고려하여 적절한 하드웨어를 준비해야 합니다.
- 레이어 정규화와 Swish 활성화 함수의 효과를 최대화하기 위해 하이퍼파라미터 튜닝이 필요합니다.

팁:
- 초기에는 얕은 네트워크로 시작하여 점진적으로 깊이를 늘려가며 성능 변화를 관찰하는 것이 유리합니다.

## 결론
이 논문은 강화 학습에서 네트워크 깊이를 확장하여 성능을 크게 향상시킬 수 있는 방법을 제시하였습니다. 이를 통해 다양한 목표 조건 문제에서 우수한 성능을 발휘할 수 있음을 실험적으로 입증하였습니다. 향후 연구에서는 실제 환경에서의 검증과 계산 비용 절감을 위한 추가 연구가 필요할 것입니다.

## 참고 자료
- 논문 링크: [arXiv:2503.14858](https://arxiv.org/abs/2503.14858)
- 코드 저장소: [GitHub](https://wang-kevin3290.github.io/scaling-crl/)