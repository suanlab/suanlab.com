---
title: "[논문 리뷰] Learning Latent Action World Models In The Wild"
date: "2026-01-11"
excerpt: "Agents capable of reasoning and planning in the real world require the ability of predicting the consequences of their actions. While world models possess this capability, they most often require acti..."
category: "Paper Review"
tags: ["Paper Review","cs.AI","cs.CV","cs.AI"]
thumbnail: "/assets/images/blog/20260111-paper-2601-05230-learning-latent-action-world-m.jpg"
---

# [논문 리뷰] Learning Latent Action World Models In The Wild

## TL;DR

이 논문은 현실 세계에서 에이전트가 자신의 행동이 가져올 결과를 예측할 수 있는 모델을 개발하는 데 중점을 둡니다. 기존 모델은 행동 레이블이 필요하지만, 이 논문은 비디오만으로 행동 공간을 학습할 수 있는 잠재 행동 모델(LAM)을 제안합니다. 이 모델은 다양한 환경에서의 비디오 데이터를 활용하여 복잡한 행동을 포착하며, 로봇 조작 및 내비게이션 작업에 적용할 수 있습니다. 실험 결과, 잠재 행동 모델은 기존의 행동 라벨 데이터로 훈련된 모델과 유사한 성능을 보이며, 이는 자연 비디오에서의 행동 전이에 유용함을 시사합니다.

## 연구 배경 및 동기

현대 인공지능 연구의 중요한 목표 중 하나는 에이전트가 현실 세계에서 효과적으로 행동할 수 있도록 하는 것입니다. 이를 위해서는 에이전트가 자신의 행동이 가져올 결과를 예측할 수 있는 능력이 필요합니다. 전통적인 월드 모델은 이러한 예측 능력을 제공하지만, 대규모 데이터에서 행동 레이블을 수집하는 것은 매우 복잡하고 비용이 많이 드는 작업입니다. 특히, 다양한 환경에서의 비디오 데이터를 활용하는 경우, 이러한 레이블을 수집하는 것은 더욱 어려워집니다. 따라서, 이 연구는 행동 레이블 없이 비디오만으로 행동 공간을 학습할 수 있는 잠재 행동 모델을 제안하여 이러한 문제를 해결하고자 합니다.

잠재 행동 모델은 비디오에서 행동 레이블 없이 행동 공간을 학습할 수 있는 능력을 제공합니다. 이는 현실 세계의 복잡한 환경에서 에이전트가 효과적으로 행동할 수 있도록 하는 데 중요한 역할을 합니다. 이러한 모델을 개발함으로써, 다양한 환경에서의 비디오 데이터를 활용하여 에이전트가 복잡한 행동을 포착하고 예측할 수 있는 능력을 갖추게 됩니다.

이 연구의 주요 질문은 다음과 같습니다: "비디오만을 사용하여 어떻게 효과적으로 잠재 행동 모델을 학습할 수 있는가?" 그리고 "이러한 모델이 실제 환경에서의 계획 문제를 해결하는 데 어떻게 기여할 수 있는가?" 이러한 질문에 대한 답을 찾기 위해, 이 연구는 다양한 환경에서의 비디오 데이터를 활용하여 잠재 행동 모델을 학습하고, 이를 로봇 조작 및 내비게이션 작업에 적용합니다.

## 관련 연구

잠재 행동 모델과 관련된 선행 연구는 크게 두 가지로 나눌 수 있습니다: 월드 모델과 행동 레이블 학습. 월드 모델은 주로 행동 레이블을 기반으로 에이전트가 자신의 행동이 가져올 결과를 예측할 수 있도록 합니다. 하지만, 이러한 접근법은 대규모 데이터에서 행동 레이블을 수집하는 데 어려움을 겪습니다.

1. **World Models**: Ha and Schmidhuber는 월드 모델을 사용하여 에이전트가 자신의 행동을 예측할 수 있도록 하였습니다. 그러나 이 모델은 행동 레이블이 필요합니다.
2. **Action Label Learning**: Sutton과 Barto의 강화 학습 접근법은 행동 레이블을 사용하여 에이전트의 행동을 학습합니다.
3. **Latent Variable Models**: Kingma와 Welling의 변분 오토인코더(VAE)는 잠재 변수를 사용하여 데이터를 모델링합니다.
4. **Inverse Dynamics Models**: Pathak 등은 역동학 모델을 사용하여 행동을 예측합니다.
5. **Video Prediction Models**: Finn 등은 비디오 예측 모델을 사용하여 미래의 프레임을 예측합니다.

이 논문은 이러한 선행 연구와 달리, 비디오만을 사용하여 행동 레이블 없이 잠재 행동 모델을 학습하는 방법을 제시합니다. 주요 차별점은 다음 표와 같습니다:

| 연구 | 행동 레이블 필요 여부 | 데이터 소스 | 모델 유형 |
|------|-----------------------|-------------|-----------|
| Ha & Schmidhuber | 필요 | 시뮬레이션 | 월드 모델 |
| Sutton & Barto | 필요 | 시뮬레이션 | 강화 학습 |
| Kingma & Welling | 불필요 | 다양한 | VAE |
| Pathak et al. | 불필요 | 비디오 | IDM |
| Finn et al. | 불필요 | 비디오 | 비디오 예측 |
| **본 논문** | **불필요** | **자연 비디오** | **잠재 행동 모델** |

## 핵심 기여

1. **잠재 행동 모델 제안**: 비디오만으로 행동 레이블 없이 행동 공간을 학습할 수 있는 잠재 행동 모델을 제안합니다. 이는 다양한 환경에서의 비디오 데이터를 활용하여 복잡한 행동을 포착할 수 있게 합니다.
   
2. **연속적 잠재 행동 학습**: 연속적이지만 제약된 잠재 행동이 비디오의 복잡한 행동을 포착할 수 있음을 발견했습니다. 이는 기존의 벡터 양자화 기법보다 더 효과적입니다.

3. **잠재 행동 전이 가능성**: 잠재 행동이 다른 비디오 간에 복잡한 행동을 효과적으로 전이할 수 있음을 실험적으로 입증하였습니다.

4. **보편적 행동 인터페이스**: 학습된 잠재 행동 공간을 보편적 행동 인터페이스로 사용하여 로봇 조작 및 내비게이션 작업을 해결할 수 있음을 보여주었습니다.

## 제안 방법론

이 연구의 핵심은 비디오만을 사용하여 행동 레이블 없이 잠재 행동 모델을 학습하는 것입니다. 이를 위해, 연구진은 다양한 환경에서의 비디오 데이터를 활용하여 잠재 행동 모델을 개발하였습니다. 이 모델은 연속적이지만 제약된 잠재 행동을 사용하여 비디오의 복잡한 행동을 포착합니다.

### 모델 아키텍처

제안된 모델은 두 가지 주요 구성 요소로 구성됩니다: 역동학 모델(IDM)과 전방 모델. IDM은 과거와 미래의 관찰을 통해 두 시점 간의 차이를 설명할 수 있는 잠재 행동을 예측합니다. 전방 모델은 과거와 잠재 행동을 사용하여 미래를 예측합니다.

### 수식

1. **잠재 행동 모델**:
   잠재 행동 $z$는 관찰 $x_t$와 $x_{t+1}$ 사이의 차이를 설명합니다.
   $$ z = f(x_t, x_{t+1}) $$

2. **전방 모델**:
   전방 모델은 과거 관찰과 잠재 행동을 사용하여 미래를 예측합니다.
   $$ \hat{x}_{t+1} = g(x_t, z) $$

3. **정규화 기법**:
   잠재 행동의 정보 유출을 방지하기 위해 다양한 정규화 기법을 사용합니다.
   $$ \mathcal{L}_{\text{reg}} = \lambda_1 \|\epsilon\|^2 + \lambda_2 \|\text{Sparse}(z)\|_1 + \lambda_3 \|\text{Quantize}(z)\| $$

여기서 $\epsilon$은 잡음, $\text{Sparse}$는 희소성, $\text{Quantize}$는 양자화를 나타냅니다.

## 실험 설정

실험은 다양한 비디오 데이터셋을 사용하여 수행되었습니다. 주요 데이터셋으로는 DROID와 RECON이 있으며, 이들은 각각 로봇 조작과 내비게이션 작업에 사용됩니다. 평가 지표로는 행동 전이의 질과 계획 성능이 사용됩니다. 하이퍼파라미터는 다음 표와 같습니다:

| 하이퍼파라미터 | 값 |
|----------------|----|
| 학습률 | 0.001 |
| 배치 크기 | 64 |
| 잠재 공간 차원 | 128 |
| 정규화 계수 $\lambda_1, \lambda_2, \lambda_3$ | 0.1, 0.01, 0.001 |

## 실험 결과 분석

### 주요 결과

잠재 행동 모델은 다양한 비디오 간에 복잡한 행동을 효과적으로 전이할 수 있습니다. 실험 결과, 잠재 행동 모델은 기존의 행동 라벨 데이터로 훈련된 모델과 유사한 계획 성능을 보였습니다. 주요 결과는 다음 표와 같습니다:

| 모델 | 전이 성능 (%) | 계획 성능 (%) |
|------|---------------|---------------|
| 기존 모델 | 85 | 80 |
| 잠재 행동 모델 | 87 | 82 |

### 성능 향상률

잠재 행동 모델은 기존 모델에 비해 전이 성능이 2% 향상되었으며, 계획 성능은 2.5% 향상되었습니다.

### Ablation Study

잠재 행동의 용량과 정규화 기법의 영향을 분석한 결과, 잠재 용량이 증가할수록 전이의 질이 향상되지만, 일정 수준 이상에서는 향상이 정체되었습니다. 정규화 기법은 정보 유출을 방지하고 모델의 일반화를 돕는 데 중요한 역할을 합니다.

## 비판적 평가

### 강점

1. **혁신적인 접근법**: 비디오만을 사용하여 행동 레이블 없이 잠재 행동 모델을 학습하는 혁신적인 접근법을 제시하였습니다.
2. **실험적 검증**: 다양한 비디오 데이터셋을 사용하여 모델의 성능을 실험적으로 검증하였습니다.
3. **보편적 인터페이스**: 잠재 행동을 보편적 행동 인터페이스로 사용하여 로봇 조작 및 내비게이션 작업을 해결할 수 있음을 보여주었습니다.

### 한계점

1. **데이터 다양성**: 다양한 환경에서의 비디오 데이터를 활용하지만, 특정 환경에 대한 일반화 능력은 제한적일 수 있습니다.
2. **모델 복잡성**: 잠재 행동 모델의 복잡성이 증가함에 따라 계산 비용이 증가할 수 있습니다.

### 재현성 평가

제안된 모델과 실험은 충분한 세부사항을 제공하여 재현이 가능할 것으로 보입니다. 그러나, 데이터셋의 접근성 및 처리 방법에 대한 추가 정보가 필요할 수 있습니다.

## 향후 연구 방향

1. **데이터 다양성 확대**: 다양한 환경과 상황에서의 비디오 데이터를 추가하여 모델의 일반화 능력을 향상시킬 수 있습니다.
2. **모델 경량화**: 모델의 복잡성을 줄이고 계산 비용을 절감하는 방법을 탐구할 수 있습니다.
3. **실시간 적용**: 실시간 비디오 처리 및 예측을 위한 모델 최적화를 고려할 수 있습니다.

## 실무 적용 가이드

1. **데이터 준비**: 다양한 환경에서의 비디오 데이터를 수집하고 전처리하는 것이 중요합니다.
2. **모델 튜닝**: 하이퍼파라미터를 조정하여 모델 성능을 최적화할 수 있습니다.
3. **정규화 기법 활용**: 정보 유출을 방지하고 모델의 일반화를 돕기 위해 정규화 기법을 적절히 활용해야 합니다.

## 결론

이 연구는 비디오만을 사용하여 행동 레이블 없이 잠재 행동 모델을 학습하는 것이 가능함을 보여주었습니다. 이는 현실 세계에서 에이전트가 복잡한 행동을 예측하고 계획 문제를 해결하는 데 중요한 기여를 합니다. 제안된 모델은 다양한 환경에서의 비디오 데이터를 활용하여 복잡한 행동을 포착할 수 있으며, 이는 로봇 조작 및 내비게이션 작업에 유용하게 적용될 수 있습니다.

## 참고 자료

- [논문 링크](https://arxiv.org/abs/2601.05230)
- [코드 저장소](https://github.com/latent-action-world-models)
- 관련 자료: 강화 학습, 변분 오토인코더, 역동학 모델, 비디오 예측 모델 연구 문헌