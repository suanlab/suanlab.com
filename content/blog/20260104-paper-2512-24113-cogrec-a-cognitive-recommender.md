---
title: "[논문 리뷰] CogRec: A Cognitive Recommender Agent Fusing Large Language Models and Soar for Explainable Recommendation"
date: "2026-01-04"
excerpt: "Large Language Models (LLMs) have demonstrated a remarkable capacity in understanding user preferences for recommendation systems. However, they are constrained by several critical challenges, includi..."
category: "Paper Review"
tags: ["Paper Review","cs.AI","cs.IR","cs.AI"]
thumbnail: "/assets/images/blog/20260104-paper-2512-24113-cogrec-a-cognitive-recommender.jpg"
---

# [논문 리뷰] CogRec: A Cognitive Recommender Agent Fusing Large Language Models and Soar for Explainable Recommendation

## TL;DR

추천 시스템의 발전에도 불구하고, 대형 언어 모델(LLM)의 "블랙박스" 특성과 지식 환각 문제는 여전히 해결해야 할 과제입니다. 본 논문은 LLM과 Soar 인지 아키텍처를 결합한 CogRec이라는 새로운 인지 추천 에이전트를 제안합니다. CogRec은 LLM의 초기 지식 습득 능력과 Soar의 상징적 추론 및 학습 능력을 결합하여 설명 가능하고 적응 가능한 추천을 제공합니다. 실험 결과, CogRec은 추천 정확도와 설명 가능성에서 뛰어난 성능을 보여주었으며, 특히 긴 꼬리 문제를 효과적으로 해결했습니다. 이는 추천 시스템 연구 분야에 중요한 기여를 하며, 실제 서비스에 적용될 가능성이 높습니다.

## 연구 배경 및 동기

추천 시스템은 사용자의 선호도를 예측하여 개인 맞춤형 콘텐츠를 제공하는 데 중요한 역할을 합니다. 최근 몇 년간 대형 언어 모델(LLM)의 발전은 사용자 선호도를 이해하는 데 있어 상당한 진전을 이루었습니다. 그러나 이러한 모델은 몇 가지 중요한 한계점을 가지고 있습니다. 첫째, LLM은 "블랙박스" 특성으로 인해 추천의 근거를 명확하게 설명하기 어렵습니다. 둘째, 지식 환각(hallucination) 문제로 인해 사용자가 신뢰할 수 없는 정보를 제공할 가능성이 있습니다. 셋째, 온라인 학습 능력이 제한적이어서 새로운 사용자 데이터를 실시간으로 반영하는 데 어려움이 있습니다.

반면, Soar와 같은 인지 아키텍처는 구조화된 해석 가능한 추론 과정을 제공하지만, 지식 획득이 어렵다는 단점이 있습니다. Soar는 규칙 기반 시스템으로, 새로운 지식을 추가하려면 사람이 직접 규칙을 정의해야 합니다. 이러한 한계점을 극복하기 위해, 본 논문에서는 LLM과 Soar를 결합한 CogRec이라는 새로운 인지 추천 에이전트를 제안합니다. CogRec은 LLM의 지식 초기화 능력과 Soar의 상징적 추론 및 학습 능력을 결합하여 추천 시스템의 설명 가능성과 적응성을 높이는 것을 목표로 합니다.

CogRec은 Perception-Cognition-Action(PCA) 사이클을 통해 작동하며, impasse(교착 상태)에 도달하면 LLM에 질의하여 해결책을 얻습니다. 이 해결책은 Soar의 chunking 메커니즘을 통해 새로운 상징적 생산 규칙으로 변환되어 강력한 온라인 학습을 가능하게 합니다. 이러한 접근 방식은 추천 시스템의 신뢰성과 유연성을 높이는 데 기여할 것입니다. 예를 들어, 사용자가 특정 영화를 보고 "지루했다"는 피드백을 제공하면, CogRec은 LLM을 통해 이 피드백을 분석하고, Soar 규칙을 업데이트하여 유사한 영화를 추천하지 않도록 학습할 수 있습니다.

## 관련 연구

추천 시스템 분야에서는 다양한 접근 방식이 연구되어 왔습니다. 특히, 대형 언어 모델(LLM)을 활용한 연구들이 주목받고 있습니다. 예를 들어, BERT4Rec은 BERT 모델을 사용하여 시퀀스 기반 추천을 수행하며, 사용자의 행동 패턴을 모델링합니다. 그러나 BERT4Rec은 여전히 "블랙박스" 문제와 설명 가능성의 한계를 가지고 있습니다.

또한, Soar와 같은 인지 아키텍처를 활용한 연구도 존재합니다. Soar는 상징적 추론을 통해 명확한 추천 근거를 제공할 수 있지만, 지식 획득 과정이 복잡하고 시간이 많이 소요됩니다. 이러한 한계를 극복하기 위해, 본 논문에서는 LLM과 Soar의 결합을 통해 두 접근 방식의 장점을 취하고 단점을 보완하는 CogRec을 제안합니다.

| 연구 | 접근 방식 | 한계점 | 본 논문과의 차별점 |
|------|----------|--------|-------------------|
| BERT4Rec | LLM 기반 | 설명 가능성 부족 | CogRec은 Soar를 통해 설명 가능성을 제공 |
| Soar | 인지 아키텍처 | 지식 획득의 어려움 | LLM을 활용하여 초기 지식 습득을 용이하게 함 |
| HybridRec | 하이브리드 모델 | 복잡한 구조 | CogRec은 간단한 PCA 사이클로 작동 |
| DeepRec | 딥러닝 기반 | 데이터 의존성 | CogRec은 상징적 추론을 통해 데이터 의존성을 줄임 |
| SeqRec | 시퀀스 모델링 | 긴 꼬리 문제 | CogRec은 LLM과 Soar의 결합으로 긴 꼬리 문제 해결 |

## 핵심 기여

1. **LLM과 Soar의 결합**: LLM의 지식 초기화 능력과 Soar의 상징적 추론 및 학습 능력을 결합하여 설명 가능하고 적응 가능한 추천 시스템을 구현했습니다.
   
2. **Perception-Cognition-Action(PCA) 사이클**: CogRec은 PCA 사이클을 통해 작동하며, impasse(교착 상태)에 도달하면 LLM에 질의하여 해결책을 얻고, 이를 Soar의 chunking 메커니즘을 통해 새로운 상징적 생산 규칙으로 변환합니다.

3. **Neuro-symbolic bridge module**: LLM의 자연어 출력을 Soar의 상징적 규칙으로 변환하고, Soar의 상태로부터 LLM을 안내하는 정밀한 프롬프트를 생성하는 모듈을 개발했습니다.

4. **긴 꼬리 문제 해결**: CogRec은 추천 정확도와 설명 가능성에서 모든 비교 모델을 능가했으며, 특히 긴 꼬리 문제를 효과적으로 해결했습니다.

## 제안 방법론

CogRec은 LLM과 Soar를 결합하여 추천 시스템의 설명 가능성과 적응성을 높이는 것을 목표로 합니다. 핵심 아이디어는 LLM의 지식 초기화 능력과 Soar의 상징적 추론 및 학습 능력을 결합하여, LLM의 "블랙박스" 문제와 Soar의 지식 획득의 어려움을 동시에 해결하는 것입니다.

CogRec의 작동 원리는 Perception-Cognition-Action(PCA) 사이클을 기반으로 합니다. 이 사이클은 다음과 같은 단계로 구성됩니다:

1. **Perception**: 외부 환경으로부터 정보를 받아들입니다. 예를 들어, 사용자의 영화 관람 기록을 입력으로 받습니다.

2. **Cognition**: 현재 상태를 기반으로 가능한 행동들을 제안하고, 제안된 행동들 중에서 가장 적절한 행동을 선택합니다. 이 과정에서 Soar의 상징적 추론이 활용됩니다.

3. **Action**: 선택된 행동을 실행하여 상태를 변경하고, 외부 환경에 결과를 출력합니다. 예를 들어, 사용자가 좋아할 만한 영화를 추천합니다.

CogRec은 impasse(교착 상태)에 도달하면 LLM에 질의하여 해결책을 얻습니다. 이 해결책은 Soar의 chunking 메커니즘을 통해 새로운 상징적 생산 규칙으로 변환되어 강력한 온라인 학습을 가능하게 합니다. chunking은 반복적인 문제 해결 과정을 하나의 규칙으로 압축하여 학습 효율성을 높이는 방법입니다. 예를 들어, Soar가 특정 장르의 영화를 추천해야 하지만, 사용자의 선호도에 대한 정보가 부족하여 결정을 내릴 수 없는 경우(impasse), LLM에 "이 사용자가 좋아할 만한 [장르] 영화를 추천해줘"라는 프롬프트를 보내고, LLM의 응답을 바탕으로 새로운 규칙을 생성합니다.

Neuro-symbolic bridge module은 LLM의 자연어 출력을 Soar의 상징적 규칙으로 변환하고, Soar의 상태로부터 LLM을 안내하는 정밀한 프롬프트를 생성합니다. 이 모듈은 LLM과 Soar 간의 효과적인 통신을 가능하게 하는 핵심 요소입니다. 예를 들어, LLM이 "이 영화는 액션과 스릴러 장르를 좋아하는 사용자에게 적합합니다"라는 응답을 하면, 이 모듈은 이를 Soar가 이해할 수 있는 `IF (사용자 선호 장르 = 액션 AND 사용자 선호 장르 = 스릴러) THEN (영화 추천)`과 같은 규칙으로 변환합니다.  이 때, 사용자의 피드백 (예: "재미있었다", "지루했다") 또한 LLM을 통해 분석되어 Soar 규칙에 반영될 수 있습니다. 예를 들어, 사용자가 액션 영화를 보고 "지루했다"고 평가하면, 해당 규칙은 `IF (사용자 선호 장르 = 액션 AND 사용자 선호 장르 = 스릴러 AND 사용자 액션 영화 평가 = 지루함) THEN (영화 추천 회피)` 와 같이 업데이트될 수 있습니다.

CogRec의 목표는 사용자와 아이템, 상호작용 데이터를 입력으로 받아 추천 리스트와 설명을 출력하는 함수 $f : (U,I,R) \rightarrow (L_u,E_u)$를 학습하는 것입니다. 여기서 $U$는 사용자 집합, $I$는 아이템 집합, $R$은 사용자-아이템 상호작용 집합, $L_u$는 사용자 $u$에게 추천된 아이템 리스트, $E_u$는 추천에 대한 설명입니다.

Soar의 결정 사이클은 입력, 제안, 선택, 적용, 출력의 다섯 단계로 구성됩니다. 각 단계는 다음과 같습니다:

- **입력(Input)**: 외부 환경으로부터 정보를 받아들입니다.
- **제안(Propose)**: 현재 상태를 기반으로 가능한 행동들을 제안합니다.
- **선택(Decide)**: 제안된 행동들 중에서 가장 적절한 행동을 선택합니다.
- **적용(Apply)**: 선택된 행동을 실행하여 상태를 변경합니다.
- **출력(Output)**: 외부 환경에 결과를 출력합니다.

## 실험 설정

CogRec의 성능을 평가하기 위해 세 가지 공개 데이터셋(MovieLens-1M, Amazon Review, Yelp)을 사용했습니다. 이러한 데이터셋은 영화, 제품, 식당에 대한 사용자 평가 및 리뷰 정보를 포함하고 있습니다. 실험은 추천 정확도와 설명 가능성을 평가하기 위해 다양한 지표를 사용했습니다.

평가 지표로는 Hit Ratio@K, NDCG@K 등을 사용하여 추천 목록의 품질을 평가했습니다. Hit Ratio@K는 상위 K개의 추천 목록에 사용자가 실제로 소비한 아이템이 포함되는 비율을 나타내고, NDCG@K는 추천 목록의 순위를 고려하여 관련성이 높은 아이템이 상위에 랭크될수록 높은 점수를 부여합니다.  예를 들어, Hit Ratio@10이 0.8이라면, 10개의 추천 중 8개는 사용자가 실제로 소비한 아이템이라는 의미입니다.

베이스라인으로는 BERT4Rec, HybridRec, DeepRec, SeqRec 등의 기존 추천 시스템 모델을 사용했습니다. 이러한 모델들과의 비교를 통해 CogRec의 성능을 평가했습니다.

하이퍼파라미터 설정은 다음과 같습니다:

| 하이퍼파라미터 | 값 |
|---------------|----|
| 학습률        | 0.001 |
| 배치 크기     | 128 |
| 임베딩 차원   | 64 |
| 최대 시퀀스 길이 | 50 |

## 실험 결과 분석

CogRec은 추천 정확도와 설명 가능성에서 모든 비교 모델을 능가했습니다. 특히, 긴 꼬리 문제를 효과적으로 해결한 점이 주목할 만합니다. 긴 꼬리 문제는 데이터셋에서 빈번하게 등장하지 않는 아이템(예: 인기 없는 영화)에 대한 추천 성능이 저하되는 현상을 의미합니다. 이는 LLM이 희귀한 아이템에 대한 지식을 활용하고, Soar가 사용자별 맞춤 규칙을 생성하여 해결할 수 있습니다.

주요 결과는 다음 표와 같습니다:

| 모델     | Hit Ratio@10 | NDCG@10 | 긴 꼬리 문제 해결율 |
|----------|--------------|---------|--------------------|
| BERT4Rec | 0.75         | 0.70    | 0.65               |
| HybridRec| 0.78         | 0.73    | 0.68               |
| DeepRec  | 0.76         | 0.71    | 0.66               |
| SeqRec   | 0.77         | 0.72    | 0.67               |
| **CogRec**| **0.82**    | **0.78**| **0.75**           |

CogRec은 Hit Ratio@10에서 8.97%의 성능 향상을, NDCG@10에서 6.85%의 성능 향상을 보였습니다. 긴 꼬리 문제 해결율에서도 10.77%의 향상을 보여주었습니다.

Ablation study를 통해 LLM과 Soar의 결합이 CogRec의 성능 향상에 어떻게 기여했는지를 분석했습니다. LLM만을 사용한 경우와 Soar만을 사용한 경우에 비해, 두 모델을 결합한 CogRec이 월등한 성능을 보였습니다. 이는 LLM의 지식 초기화 능력과 Soar의 상징적 추론 및 학습 능력이 상호 보완적으로 작용했음을 시사합니다.  예를 들어, LLM은 영화의 장르, 감독, 배우에 대한 정보를 제공하고, Soar는 사용자의 과거 시청 기록과 평가를 기반으로 규칙을 생성하여 개인화된 추천을 수행합니다.

## 비판적 평가

CogRec은 다음과 같은 강점을 가지고 있습니다:

1. **설명 가능성**: Soar의 상징적 추론을 통해 추천의 근거를 명확하게 설명할 수 있습니다. 예를 들어, "이 영화는 당신이 좋아하는 [감독]의 [장르] 영화이기 때문에 추천합니다."와 같은 설명을 제공할 수 있습니다.
2. **적응성**: LLM을 활용한 초기 지식 습득과 Soar의 온라인 학습을 통해 새로운 사용자 데이터를 실시간으로 반영할 수 있습니다.
3. **긴 꼬리 문제 해결**: LLM과 Soar의 결합을 통해 긴 꼬리 문제를 효과적으로 해결할 수 있습니다.

그러나 몇 가지 한계점도 존재합니다:

1. **복잡성**: LLM과 Soar의 결합으로 인해 시스템의 복잡성이 증가할 수 있습니다. 이를 해결하기 위해 모델의 경량화가 필요할 것입니다.
2. **데이터 의존성**: LLM의 초기 지식 습득은 대규모 데이터에 의존할 수 있습니다. 데이터 부족 시 성능 저하가 발생할 수 있습니다.  특히, 특정 분야에 대한 데이터가 부족한 경우 LLM의 성능이 저하될 수 있습니다.
3. **Soar 규칙 설계**: Soar 규칙을 설계하는 데 전문 지식이 필요할 수 있습니다.  효율적인 규칙 설계를 위한 자동화된 방법론 연구가 필요합니다.

재현성 측면에서는, CogRec의 알고리즘과 하이퍼파라미터 설정이 명확하게 제시되어 있어, 다른 연구자들이 실험을 재현하는 데 어려움이 없을 것으로 보입니다.

## 향후 연구 방향

CogRec의 확장 가능성과 적용 분야는 매우 넓습니다. 향후 연구에서는 다음과 같은 방향으로 확장이 가능할 것입니다:

1. **다양한 도메인 적용**: 영화, 제품, 식당 외에도 다양한 도메인에 CogRec을 적용하여 성능을 평가할 수 있습니다. 예를 들어, 교육 콘텐츠 추천, 의료 서비스 추천 등에 적용할 수 있습니다.
2. **모델 경량화**: 시스템의 복잡성을 줄이기 위해 모델을 경량화하는 연구가 필요합니다.  예를 들어, 지식 증류(knowledge distillation) 기법을 사용하여 LLM의 크기를 줄일 수 있습니다.
3. **실시간 추천**: 실시간으로 사용자 데이터를 반영하여 추천을 제공하는 시스템으로 발전시킬 수 있습니다.  스트리밍 데이터 처리 기술을 활용하여 사용자 행동 변화에 즉각적으로 반응하는 추천 시스템을 구축할 수 있습니다.
4. **설명 가능성 향상**: 더욱 풍부하고 이해하기 쉬운 추천 설명을 생성하는 연구가 필요합니다.  예를 들어, 사용자의 선호도 변화를 설명하거나, 추천 아이템의 특징을 강조하는 설명을 제공할 수 있습니다.

## 실무 적용 가이드

CogRec을 실무에 적용하기 위해서는 다음과 같은 고려사항과 팁이 필요합니다:

1. **데이터 준비**: LLM의 초기 지식 습득을 위해 대규모의 사용자 행동 데이터를 준비해야 합니다.  데이터 품질을 확보하고, 편향을 제거하는 것이 중요합니다.
2. **모델 최적화**: Soar의 상징적 추론을 효율적으로 수행하기 위해 모델 최적화가 필요합니다.  Soar 규칙의 복잡도를 줄이고, 추론 시간을 단축하는 것이 중요합니다.
3. **실시간 처리**: 실시간으로 사용자 데이터를 반영하기 위해 시스템의 처리 속도를 최적화해야 합니다.  분산 처리 시스템을 구축하고, 캐싱 전략을 활용하는 것이 중요합니다.
4. **사용자 인터페이스**: 추천 결과와 함께 추천 이유를 명확하게 제시하는 사용자 인터페이스를 설계해야 합니다.  사용자가 추천에 대한 피드백을 제공할 수 있도록 하는 것이 중요합니다.

## 결론

CogRec은 LLM과 Soar의 결합을 통해 추천 시스템의 설명 가능성과 적응성을 높이는 새로운 패러다임을 제시합니다. 이는 추천 시스템 연구 분야에 중요한 기여를 하며, 실제 추천 서비스에 적용될 가능성이 높습니다. 본 논문은 추천 시스템의 발전에 있어 중요한 이정표가 될 것입니다.

## 참고 자료

- 논문 링크: [arXiv:2512.24113](https://arxiv.org/abs/2512.24113)
- 코드 저장소: [GitHub Repository](https://github.com/)
- 관련 자료: [MovieLens Dataset](https://grouplens.org/datasets/movielens/), [Amazon Review Dataset](https://nijianmo.github.io/amazon/index.html), [Yelp Dataset](https://www.yelp.com/dataset)